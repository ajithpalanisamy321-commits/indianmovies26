# -*- coding: utf-8 -*-
"""Indian_movie_details.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1APTufnlU7fbRLVoQqLD1vXjBK9jRlzBU
"""

!pip install numpy
!pip install pandas
!pip install matplotlib
!pip install seaborn

"""IMPORTING LIBRARIES"""

import os
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import warnings
warnings.filterwarnings("ignore")

"""LOADING DATABASE"""

movie_df = pd.read_csv("/indian movies.csv")

display(movie_df.head())

print("Shape:", movie_df.shape)

movie_df.head(10)

movie_df.tail(5)



#Display first 5 rows [0->4]
movie_df.head()

movie_df.iloc[0:5]

movie_df.columns



#to Get information of data
movie_df.info()

"""**Missing Values Summary**"""

# Missing values
print(movie_df.isna().sum())

# Unique values in each column
print(movie_df.nunique())

# Missing Values Calculation
movie_df.isnull().sum()

# calculate the percentage of missing values in each column
(movie_df.isnull().sum()/(len(movie_df)))*100

"""**DUPLICATE FINDINGS**"""

# Duplicate Records

# Countig the duplicates
duplicate_count = movie_df.duplicated().sum()
print("Total Duplicate Rows:", duplicate_count)

# Display sample duplicates
if duplicate_count > 0:
    display(movie_df[movie_df.duplicated()].head())

# Removing duplicates values
movie_df = movie_df.drop_duplicates()
print("\nDuplicates removed. New shape:", movie_df.shape)

"""Detect Outliers"""

num_cols = movie_df.select_dtypes(include=['int64', 'float64']).columns

total_outliers = 0  # To count total outliers in dataset
outlier_details = {}  # To store which column has outliers

for col in num_cols:
    Q1 = movie_df[col].quantile(0.25)
    Q3 = movie_df[col].quantile(0.75)
    IQR = Q3 - Q1

    lower = Q1 - 1.5 * IQR
    upper = Q3 + 1.5 * IQR

    outliers = movie_df[(movie_df[col] < lower) | (movie_df[col] > upper)]
    count = len(outliers)

    if count > 0:
        outlier_details[col] = count
        total_outliers += count

# ===========================
#       FINAL OUTPUT
# ===========================

if total_outliers > 0:
    print(f"\nTotal Outliers in Entire Dataset: {total_outliers}\n")
    print("Columns with Outliers:")
    for col, cnt in outlier_details.items():
        print(f"- {col}: {cnt} outliers")
else:
    print("✅ No outliers found in the entire dataset!")

"""Finding Inconsistent Records – Negative Values (movie_df)"""

# 1) Negative values (not logical for movie dataset)
num_cols = movie_df.select_dtypes(include=['int64', 'float64']).columns

# Find negative values in any numeric column
neg_values = movie_df[num_cols][movie_df[num_cols] < 0].dropna(how='all')

#checking the negative values
if len(neg_values) > 0:
    print("\n❌ Negative Values Found:")
    display(neg_values)   # shows ALL negative-value rows
else:
    print("✅ No Negative Values Found in the Dataset.")

#Inconsistent categories
if 'Music' in movie_df.columns:
    print(movie_df['music'].value_counts().head(5))
    print(movie_df['music'].unique())
else:
    print("music column not found.")

"""DERIVED METRICS"""

movie_df['title_length'] = movie_df['Movie Name'].astype(str).apply(len)

movie_df[['Movie Name', 'title_length']].head()

"""## Filtering Data for Targeted Analysis


"""

# ==== SIMPLE FEATURE ENGINEERING FOR MOVIE DATASET ====

# 1. Length of movie name
movie_df['title_length'] = movie_df['Movie Name'].astype(str).apply(len)

# 2. Word count of movie name
movie_df['title_word_count'] = movie_df['Movie Name'].astype(str).apply(lambda x: len(x.split()))

# Clean 'Timing(min)' column and convert to numeric
movie_df['Timing(min)_numeric'] = movie_df['Timing(min)'].astype(str).str.replace(' min', '', regex=False).str.replace(',', '', regex=False).replace('-', '0').astype(float)

# 3. Runtime Category (Simple)
# Short = ≤ 90 mins
# Medium = 91–150 mins
# Long = > 150 mins
movie_df['runtime_category'] = np.where(
    movie_df['Timing(min)_numeric'] <= 90, 'Short',
    np.where(movie_df['Timing(min)_numeric'] <= 150, 'Medium', 'Long')
)

# 4. Clean votes (remove commas and convert to numeric)
movie_df['votes_int'] = (
    movie_df['Votes']
    .astype(str)
    .str.replace(',', '', regex=False)
    .str.replace('$', '', regex=False)
    .str.replace('M', '', regex=False)
    .replace('-', '0')
    .astype(float)
)

# Show sample
movie_df[['Movie Name','title_length','title_word_count','Timing(min)_numeric','runtime_category','Votes','votes_int']].head()

"""STATISTICAL ANALYSIS

DESCRIPTIVE STATISTICS
"""

# 1. Create Movie Duration Category

movie_df['Movie_Duration'] = np.where(
    movie_df['Timing(min)_numeric'] <= 90, "Short",
    np.where(movie_df['Timing(min)_numeric'] <= 150, "Medium", "Long")
)

print("New Feature 'Movie_Duration' Created Successfully!")


# 2. Check Available Columns

print("\nAvailable Columns:")
print(movie_df.columns.tolist())


# 3. Verify if column created

if 'Movie_Duration' in movie_df.columns:
    print("\nUnique Categories:", movie_df['Movie_Duration'].unique())
    print("Number of Categories:", movie_df['Movie_Duration'].nunique())
else:
    print("\nColumn 'Movie_Duration' NOT FOUND")

movie_df['Year'] = movie_df['Year'].replace('-', np.nan)
movie_df['Year'] = pd.to_numeric(movie_df['Year'], errors='coerce')
median_year = movie_df['Year'].median()
movie_df['Year'].fillna(median_year, inplace=True)

movie_df['Rating(10)'] = movie_df['Rating(10)'].replace('-', np.nan)
movie_df['Rating(10)'] = pd.to_numeric(movie_df['Rating(10)'], errors='coerce')
median_rating = movie_df['Rating(10)'].median()
movie_df['Rating(10)'].fillna(median_rating, inplace=True)

print(" 'Year' and 'Rating(10)' columns cleaned and converted successfully.")
print(movie_df[['Year', 'Rating(10)']].head())

"""F-TEST"""

from scipy.stats import f_oneway

# Extract ratings for each movie duration category
short_ratings = movie_df[movie_df['Movie_Duration'] == 'Short']['Rating(10)']
medium_ratings = movie_df[movie_df['Movie_Duration'] == 'Medium']['Rating(10)']
long_ratings = movie_df[movie_df['Movie_Duration'] == 'Long']['Rating(10)']

# Perform one-way ANOVA F-test
f_statistic, p_value = f_oneway(short_ratings, medium_ratings, long_ratings)

print(f"F-statistic: {f_statistic:.2f}")
print(f"P-value: {p_value:.3f}")

if p_value < 0.05:
    print("\nBased on the F-test, there is a statistically significant difference in mean ratings across movie duration categories (p < 0.05).")
else:
    print("\nBased on the F-test, there is no statistically significant difference in mean ratings across movie duration categories (p >= 0.05).")

"""T-TEST"""

from scipy.stats import ttest_ind

# Extract ratings for 'Short' and 'Medium' duration movies
short_duration_ratings = movie_df[movie_df['Movie_Duration'] == 'Short']['Rating(10)']
medium_duration_ratings = movie_df[movie_df['Movie_Duration'] == 'Medium']['Rating(10)']

# Perform independent samples t-test
t_statistic, p_value = ttest_ind(short_duration_ratings, medium_duration_ratings, equal_var=False) # Assuming unequal variances

print(f"T-statistic: {t_statistic:.2f}")
print(f"P-value: {p_value:.3f}")

if p_value < 0.05:
    print("\nBased on the t-test, there is a statistically significant difference in mean ratings between Short and Medium duration movies (p < 0.05).")
else:
    print("\nBased on the t-test, there is no statistically significant difference in mean ratings between Short and Medium duration movies (p >= 0.05).")

"""CHI-SQUARE TEST"""

from scipy.stats import chi2_contingency
import pandas as pd

# Create a contingency table between 'Language' and 'Movie_Duration'
contingency_table = pd.crosstab(movie_df['Language'], movie_df['Movie_Duration'])

# Perform the Chi-square test
chi2_statistic, p_value, dof, expected_frequencies = chi2_contingency(contingency_table)

print("Chi-square Statistic:", chi2_statistic)
print("P-value:", p_value)
print("Degrees of Freedom:", dof)
# print("Expected Frequencies:\n", expected_frequencies) # Uncomment to see expected frequencies

if p_value < 0.05:
    print("\nBased on the Chi-square test, there is a statistically significant association between Language and Movie Duration (p < 0.05).")
else:
    print("\nBased on the Chi-square test, there is no statistically significant association between Language and Movie Duration (p >= 0.05).")

hindi_movies_df = movie_df[movie_df['Language'].str.contains('hindi', case=False, na=False)]
movies_2000_2010_df = movie_df[(movie_df['Year'] >= 2000) & (movie_df['Year'] <= 2010)]

print("\n--- Hindi Movies DataFrame ---")
print(hindi_movies_df.head())
print("Shape of hindi_movies_df:", hindi_movies_df.shape)

print("\n--- Movies from 2000-2010 DataFrame ---")
print(movies_2000_2010_df.head())
print("Shape of movies_2000_2010_df:", movies_2000_2010_df.shape)

numerical_cols = ['title_length', 'title_word_count', 'Timing(min)_numeric', 'votes_int', 'Rating(10)', 'Year']
descriptive_stats = movie_df[numerical_cols].describe()

print("Descriptive statistics for numerical features:")
print(descriptive_stats)

import matplotlib.pyplot as plt
import seaborn as sns

numerical_cols = ['title_length', 'title_word_count', 'Timing(min)_numeric',
                  'votes_int', 'Rating(10)', 'Year']

for col in numerical_cols:
    plt.figure(figsize=(12, 5))

    plt.subplot(1, 2, 1) # 1 row, 2 columns, first plot
    sns.histplot(movie_df[col], kde=True)
    plt.title(f'{col} Distribution')
    plt.xlabel(col)
    plt.ylabel('Frequency')

    plt.subplot(1, 2, 2) # 1 row, 2 columns, second plot
    sns.boxplot(y=movie_df[col])
    plt.title(f'{col} Box Plot')
    plt.ylabel(col)

    plt.tight_layout()
    plt.show()

"""## Univariate Analysis - Categorical Features

### Subtask:
Calculate and display value counts for categorical features ('runtime_category', 'Movie_Duration', 'Language', 'Genre'). Visualize their distributions using bar plots, ensuring appropriate labels and titles for clarity.

**Reasoning**:
I will define the list of categorical columns and then iterate through them to calculate and display value counts, followed by generating a bar plot for each to visualize their distributions with appropriate labels and titles.
"""

categorical_cols = ['runtime_category', 'Movie_Duration', 'Language', 'Genre']

for col in categorical_cols:
    print(f"\n--- Value Counts for {col} ---")
    print(movie_df[col].value_counts())

    plt.figure(figsize=(10, 6))
    sns.countplot(data=movie_df, x=col, palette='viridis')
    plt.title(f'Distribution of {col}')
    plt.xlabel(col)
    plt.ylabel('Count')

    # Rotate x-axis labels for better readability if needed
    if col in ['Language', 'Genre']:
        plt.xticks(rotation=90)

    plt.tight_layout()
    plt.show()

categorical_cols = ['runtime_category', 'Movie_Duration', 'Language', 'Genre']

for col in categorical_cols:
    print(f"\n--- Value Counts for {col} ---")
    print(movie_df[col].value_counts())

    plt.figure(figsize=(10, 6))
    sns.countplot(data=movie_df, x=col, hue=col, palette='viridis', legend=False)
    plt.title(f'Distribution of {col}')
    plt.xlabel(col)
    plt.ylabel('Count')

    # Rotate x-axis labels for better readability if needed
    if col in ['Language', 'Genre']:
        plt.xticks(rotation=90)

    plt.tight_layout()
    plt.show()

"""## Bivariate Analysis - Correlation Heatmap



"""

numerical_features = ['title_length', 'title_word_count', 'Timing(min)_numeric', 'votes_int', 'Rating(10)', 'Year']

correlation_matrix = movie_df[numerical_features].corr()

plt.figure(figsize=(10, 8))
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=".2f", linewidths=.5)
plt.title('Correlation Matrix of Numerical Features')
plt.show()

"""## Bivariate Analysis - Scatter Plots

### Subtask:
Create scatter plots to explore relationships between pairs of numerical features. For example, visualize the relationship between 'votes_int' and 'Rating(10)' to see if higher votes correlate with higher ratings.

**Reasoning**:
I will create a scatter plot to visualize the relationship between 'votes_int' and 'Rating(10)' as requested by the subtask, adding appropriate labels and title for clarity.
"""

plt.figure(figsize=(10, 6))
sns.scatterplot(data=movie_df, x='votes_int', y='Rating(10)', alpha=0.5)
plt.title('Relationship between Total Votes and Movie Rating')
plt.xlabel('Total Votes (votes_int)')
plt.ylabel('Rating (10)')
plt.grid(True)
plt.show()

"""**Reasoning**:
As requested by the subtask to repeat for other interesting pairs of numerical features, I will now visualize the relationship between 'Timing(min)_numeric' and 'Rating(10)' to explore if movie duration correlates with ratings.


"""

plt.figure(figsize=(10, 6))
sns.scatterplot(data=movie_df, x='Timing(min)_numeric', y='Rating(10)', alpha=0.5)
plt.title('Relationship between Movie Duration and Rating')
plt.xlabel('Movie Duration (minutes)')
plt.ylabel('Rating (10)')
plt.grid(True)
plt.show()

"""**Reasoning**:
Following the instruction to repeat scatter plots for other interesting numerical feature pairs, I will now visualize the relationship between 'Year' and 'Rating(10)' to observe any trends in ratings over time.


"""

plt.figure(figsize=(10, 6))
sns.scatterplot(data=movie_df, x='Year', y='Rating(10)', alpha=0.5)
plt.title('Relationship between Year and Movie Rating')
plt.xlabel('Year')
plt.ylabel('Rating (10)')
plt.grid(True)
plt.show()

"""## Bivariate Analysis"""

plt.figure(figsize=(10, 6))
sns.boxplot(data=movie_df, x='runtime_category', y='Rating(10)', palette='viridis')
plt.title('Distribution of Rating(10) by Runtime Category')
plt.xlabel('Runtime Category')
plt.ylabel('Rating (10)')
plt.grid(axis='y')
plt.show()

plt.figure(figsize=(10, 6))
sns.boxplot(data=movie_df, x='runtime_category', y='Rating(10)', hue='runtime_category', palette='viridis', legend=False)
plt.title('Distribution of Rating(10) by Runtime Category')
plt.xlabel('Runtime Category')
plt.ylabel('Rating (10)')
plt.grid(axis='y')
plt.show()

plt.figure(figsize=(10, 6))
sns.boxplot(data=movie_df, x='runtime_category', y='votes_int', hue='runtime_category', palette='viridis', legend=False)
plt.title('Distribution of Votes by Runtime Category')
plt.xlabel('Runtime Category')
plt.ylabel('Total Votes (votes_int)')
plt.grid(axis='y')
plt.show()

top_10_languages = movie_df['Language'].value_counts().nlargest(10).index
filtered_language_df = movie_df[movie_df['Language'].isin(top_10_languages)]

plt.figure(figsize=(12, 7))
sns.boxplot(data=filtered_language_df, x='Language', y='Rating(10)', hue='Language', palette='tab10', legend=False)
plt.title('Distribution of Rating(10) by Top 10 Languages')
plt.xlabel('Language')
plt.ylabel('Rating (10)')
plt.xticks(rotation=45, ha='right')
plt.grid(axis='y')
plt.tight_layout()
plt.show()

"""**MULTIVARIATE ANALYSIS**"""

plt.figure(figsize=(12, 6))
sns.boxplot(data=movie_df, x='runtime_category', y='Rating(10)', hue='Genre')
plt.title('Rating Distribution by Runtime Category & Genre')
plt.xlabel('Runtime Category')
plt.ylabel('Rating (10)')
plt.legend(title='Genre', bbox_to_anchor=(1.02, 1), loc='upper left')
plt.grid(axis='y')
plt.show()

plt.figure(figsize=(10, 6))
sns.heatmap(movie_df.corr(numeric_only=True), annot=True, cmap='coolwarm')
plt.title('Correlation Heatmap of Numeric Variables')
plt.show()

grouped_data = movie_df.groupby(['Genre', 'runtime_category'])['Rating(10)'].mean().reset_index()

plt.figure(figsize=(12, 6))
sns.barplot(data=grouped_data, x='Genre', y='Rating(10)', hue='runtime_category')
plt.title('Average Rating by Genre & Runtime Category')
plt.xticks(rotation=45)
plt.xlabel('Genre')
plt.ylabel('Average Rating (10)')
plt.legend(title='Runtime Category')
plt.show()